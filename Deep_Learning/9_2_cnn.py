# -*- coding: utf-8 -*-
"""9_2_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X1pHyXVpTVCCXVtxAWAjI093MUSwRJbv
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
# %matplotlib inline

from tensorflow.keras.datasets import mnist
(X_train, y_train), (X_test, y_test) = mnist.load_data()

X_train.shape

image = X_train[0]
plt.imshow(image, 'gray')
plt.show()

image.shape

# 실제 텐서플로우의 CNN은 4차원으로 데이터를 받는다.
# 차원 확장
image = image[tf.newaxis, ..., tf.newaxis]
image.shape

"""# CNN

## Convolusion 레이어의 하이퍼 파라미터
* filters : 필터의 개수
    * 필터의 개수가 많다는 이야기는 뉴런의 개수를 결정짓는 말과 똑같다.
* kernel_size : 필터의 가로 세로 크기
    * 보통 3x3 ~ 5x5를 사용함.
* strides : 필터가 몇개의 픽셀을 스킵하면서 지나갈 것인지
* padding : VALID패딩 -> 패딩 있음 / SAME패딩 -> 패딩 없음
* activation : 활성화 함수 사용하기, 나중에 레이어로 추가 가능
"""

tf.keras.layers.Conv2D(filters=3, kernel_size=(3, 3), strides=(1, 1), padding='SAME', activation='relu')

# 파라미터가 정사각형이라면 튜플로 지정 안해도 됨.
tf.keras.layers.Conv2D(filters=3, kernel_size=3, strides=1, padding='SAME', activation='relu')

image = tf.cast(image, dtype=tf.float32)
image.shape

layer = tf.keras.layers.Conv2D(filters=5, kernel_size=(3, 3), strides=(1, 1), padding='SAME')
layer

output = layer(image)
output.shape

_, axes = plt.subplots(nrows=1, ncols=6, figsize=(20, 10))

axes[0].imshow(image[0, ..., 0], cmap='gray')
axes[0].set_title("original Image")
for idx, ax in enumerate(axes[1:]):
    ax.set_title("Output {}".format(idx))
    ax.imshow(output[0, ..., idx], cmap='gray')
plt.show()

"""## Filter 확인하기"""

# 0번에는 가중치 1번에는 편향
weights = layer.get_weights()
weights[0].shape, weights[1].shape

"""(필터의 세로크기 필터의 가로크기, 채널수, 필터의 개수)

## 필터 시각화
"""

_, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 10))

for idx, ax in enumerate(axes):
    ax.set_title("filter {}".format(idx))
    ax.imshow(weights[0][:, :, 0, idx], 'gray')
plt.show()

"""## ReLU 레이어 적용하기"""

output.shape

np.min(output), np.max(output)

act_layer = tf.keras.layers.ReLU()
act_output = act_layer(output)
act_output.shape

_, axes = plt.subplots(nrows=1, ncols=6, figsize=(20, 10))

axes[0].imshow(image[0, ..., 0], cmap='gray')
axes[0].set_title("original Image")
for idx, ax in enumerate(axes[1:]):
    ax.set_title("Output {}".format(idx))
    ax.imshow(act_output[0, ..., idx], cmap='gray')
plt.show()

"""## MaxPooling 레이어
- 약간 움직여도 같은 이미지임을 찾아준다.
"""

pool_layer = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='SAME')
pool_output = pool_layer(act_output)
pool_output.shape

_, axes = plt.subplots(nrows=1, ncols=6, figsize=(20, 10))

axes[0].imshow(image[0, ..., 0], cmap='gray')
axes[0].set_title("original Image")
for idx, ax in enumerate(axes[1:]):
    ax.set_title("Output {}".format(idx))
    ax.imshow(pool_output[0, ..., idx], cmap='gray')
plt.show()

"""## flatten Layer"""

flatten_layer = tf.keras.layers.Flatten() 
flatten_output = flatten_layer(pool_output)
flatten_output.shape

"""## Dense 레이어
- Affine 레이어
- 행렬 내적 연산
"""

dense_layer = tf.keras.layers.Dense(32, activation='relu')
dense_output = dense_layer(flatten_output)
dense_output.shape
# 한장의 이미지가 들어와서 32개의 출력을 낼 것.

dense_layer2 = tf.keras.layers.Dense(10, activation='relu')
dense_output2 = dense_layer2(dense_output)
dense_output2.shape

"""## 초간단 CNN레이어 연결하기
* 사용할 데이터의 feature 형상 지정 -> input_shape
    * 28, 28, 1
* 분류할 데이터 개수 미리 지정 -> num_classes
    * 데이터가 10개 들어갈 것임.
"""

from tensorflow.keras import layers

input_shape = (28, 28, 1)
num_classes = 10

# 1. 텐서 플로우를 활용한 신경망의 시작은 InputLayer로 시작한다.
inputs = layers.Input(shape=input_shape)

# 2. CNN 레이어 구축 -> Feature Extraction
# strides를 입력하지 않으면 기본적으로 1이 할당됨.
net = layers.Conv2D(32, 3, padding='SAME')(inputs)
net = layers.Activation('relu')(net)
net = layers.Conv2D(32, 3, padding='SAME')(net)
net = layers.Activation('relu')(net)
net = layers.MaxPool2D((2, 2))(net)

# 과적합 방지를 위해서 dropout
# Dropout(0.25) 25%의 데이터를 drop -> 0으로 만들어 버리겠다.
net = layers.Dropout(0.25)(net)


net = layers.Conv2D(64, 3, padding='SAME')(net)
net = layers.Activation('relu')(net)
net = layers.Conv2D(64, 3, padding='SAME')(net)
net = layers.Activation('relu')(net)
net = layers.MaxPool2D((2, 2))(net)
net = layers.Dropout(0.25)(net)


# 3. Dense Layer를 활용 -> Fully Connected
net = layers.Flatten()(net)
# z를 구하는 구간.
net = layers.Dense(512)(net)
net = layers.Activation('relu')(net)
net = layers.Dropout(0.25)(net)

# 출력층 설계
net = layers.Dense(num_classes)(net)
net = layers.Activation('softmax')(net)

model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')

model.summary()

"""## 모델을 평가할 수 있는 최적화 함수 선정
- Loss Function(MSE, CEE)
- Optimization(SGD, ADAM, RMSPROPS, lbfgs, Momentum 등등....
- Metrics(평가 기준) - 정확도로 많이 함

### Loss Function 선정하기
- MSE는 회귀문제
- CEE는 다중분류

- Binary classification( 이진 분류시에 많이 사용 )
- Categorical Classification( 이진 분류 이상에서 광범위하게 사용 )
"""

# 이진 분류를 위한 CEE
loss = 'binary_crossentropy'

# 다중 분류를 위한 CEE
loss = 'categorical_crossentropy'

"""#### categorical CEE / sparse categorical CEE

- categorical_crossentropy : 원핫 인코딩 된 레이블에 사용 (예전에 해본적있음)
- sparse_categorical_crossentropy : 원핫 인코딩이 안된 레이블에 사용
"""

y_train[:5]

# 케라스에서 각종 손실함수 불러오기
loss_func = tf.keras.losses.sparse_categorical_crossentropy
loss_func

"""### Metric (평가기준)
- accuracy(정확도 확인)
"""

metrics = ['accuracy'] # 또는 [acc]

tf.keras.metrics.Accuracy()

"""### Optimizer
- sgb (기본)
- rmsprop (adam이 잘 안되면 시도해 볼만함.)
- adam(거의 모든 상황에서 잘 작동함)
- lbfgs
"""

optm = tf.keras.optimizers.Adam()

"""### Model Compile
1. 레이어를 쌓아서 네트워크 준비
2. 손실, 평가, 최적화 준비하기
3. 모델 컴파일
"""

# 실제 빌드 과정
# 최적화 계획 손실 등 모두 완료된 상태
model.compile(optimizer=optm, loss=loss_func, metrics=metrics)

X_train.shape

X_test.shape

X_train = X_train[..., tf.newaxis]
X_test = X_test[..., tf.newaxis]

X_train.shape, X_test.shape

"""### 스케일링 작업
- 실수를 넣어줘야하기 때문에 스케일링 같은 것을 한다.
- 안하면 훈련이 잘 안됨.
- 매우매우 권장됨.
"""

X_train_scaled = X_train / 255.0
X_test_scaled = X_test / 255.0

np.min(X_train_scaled), np.max(X_train_scaled)

np.min(X_test_scaled), np.max(X_test_scaled)

"""## 학습 시작
- 에폭
- 배치사이즈 설정하기
"""

num_epoche = 10
batch_size = 32

model.fit(X_train_scaled, y_train, batch_size=batch_size, epochs=num_epoche, shuffle=True)

plt.imshow(image[0, :, :, 0], 'gray')
plt.show()

model.predict(image)

image = X_test_scaled[0, :, :, 0]

plt.imshow(image, 'gray')
plt.show()

y_test[0]

image = image[tf.newaxis, ..., tf.newaxis] # 훈련할 때 4차원으로 훈련했으니까 테스트 할 때도 4차원으로 테스트
image.shape

predictions = model.predict(image)
predictions

np.argmax(predictions)

for proba in predictions[0]:
    print("{:.10f}".format(proba))

# tensorflow 원-핫 인코딩
tf.one_hot([0, 1, 2], 10)

