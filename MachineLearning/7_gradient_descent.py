# -*- coding: utf-8 -*-
"""7_Gradient_descent.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z1RXgaENYLVzmprrrj-hSoBJmwcFpZss
"""

import numpy as np

# 미분 배치를 안쓴다.
def _numerical_gradient_no_batch(f, x):
    h = 1e-4 # 0.0001
    grad = np.zeros_like(x) # x와 형상이 같은 배열을 생성
    for idx in range(x.size):
        tmp_val = x[idx]
        # f(x+h) 계산
        x[idx] = float(tmp_val) + h
        fxh1 = f(x)
        # f(x-h) 계산
        x[idx] = tmp_val - h 
        fxh2 = f(x) 
        grad[idx] = (fxh1 - fxh2) / (2*h)
        x[idx] = tmp_val # 값 복원
    return grad

# (편)미분
def numerical_gradient(f, X):
    if X.ndim == 1:
        return _numerical_gradient_no_batch(f, X)
    else:
        grad = np.zeros_like(X)
        for idx, x in enumerate(X):
            grad[idx] = _numerical_gradient_no_batch(f, x)
        return grad

"""
    f : 비용함수 또는 손실함수(Cost function, Loss function)
    init_x : 초기값
    lr : 학습률
    step_num : 갱신할 횟수
"""

def gradient_descent(f, init_x, lr=0.01, step_num=100):
    x = init_x

    # step_num만큼 반복학습
    for i in range(step_num):
        grad = numerical_gradient(f, x) # x를 미분하고
        x -= lr * grad # 학습률을 곱해서 x를 업데이트
    return x

"""최소값과 기울기를 알아내는 경사법 사용"""

# x0가 -3.0이고 x1이 4.0일 때
def function_2(x):
    return x[0]**2 + x[1]**2

init_x = np.array([-3.0, 4.0])
gradient_descent(function_2, init_x, lr=0.1, step_num=100)

"""## 시각화"""

import numpy as np
import matplotlib.pylab as plt


def gradient_descent(f, init_x, lr=0.01, step_num=100):
    x = init_x
    x_history = []

    for i in range(step_num):
        x_history.append( x.copy() )

        grad = numerical_gradient(f, x)
        x -= lr * grad

    return x, np.array(x_history)

init_x = np.array([-3.0, 4.0])    

lr = 0.1
step_num = 20
x, x_history = gradient_descent(function_2, init_x, lr=lr, step_num=step_num)

plt.plot( [-5, 5], [0,0], '--b')
plt.plot( [0,0], [-5, 5], '--b')
plt.plot(x_history[:,0], x_history[:,1], 'o')

plt.xlim(-3.5, 3.5)
plt.ylim(-4.5, 4.5)
plt.xlabel("X0")
plt.ylabel("X1")
plt.show()

# 학습률이 너무 큰 예. lr = 10.0
init_x = np.array([-3.0, 4.0])
result, _ = gradient_descent(function_2, init_x=init_x, lr=10.0, step_num=100)
print("Learning Rate 10.0 : {}".format(result))


# 학습률이 너무 작은 예. lr = 1e-10
init_x = np.array([-3.0, 4.0])
result, _ = gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100)
print("Learning Rate 1e-10 : {}".format(result))

import sys, os
sys.path.append(os.pardir)
import numpy as np
from common.functions import softmax, cross_entropy_error
from common.gradient import numerical_gradient

class SimpleNet:
    def __init__(self):
        self.W = np.random.randn(2, 3) # 2 x 3 형태로 정규분포로 이루어진 가중치의 초기값 생성.
        
    def predict(self, x):
        return np.dot(x, self.W) # 입력값과 가중치의 내적.
    
    def loss(self, x, t):
        z = self.predict(x)
        y = softmax(z)
        loss = cross_entropy_error(y, t)
        
        return loss

net = SimpleNet()
print("가중치 확인 : \n{}".format(net.W))

x = np.array([0.6, 0.9])
p = net.predict(x)

print("단순 예측 값 : {}".format(p))

print("최댓값의 인덱스 : {}".format(np.argmax(p))) # 최댓값의 인덱스

t = np.array([0, 1, 0]) # 정답 레이블
net.loss(x, t)

def f(W):
    return net.loss(x, t)

dW = numerical_gradient(f, net.W)
dW 

# loss의 변화량
# x11에서는 0.05증가함, x21에서는 0.07증가함.
# 가장 변화량이 작은 건 첫번째 값.
# 가장 변화량이 큰 건 5번째 값이다.

"""# MNIST 데이터셋 분류 신경망 만들기"""

from common.functions import *
from common.gradient import numerical_gradient

class TwoLayerNet:

    # 신경망 초기화
    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):
        
        # 사용할 매개변수 준비, 매개변수에 대한 초기 설정
        # 가중치는 정규분포로 이루어진 랜덤값 사용
        # 편향은 0으로 초기화 하는 것이 일반적.

        # 가중치들을 담아놓을 딕셔너리
        self.params = {}

        # 1층(은닉층)의 매개변수 설정
        # 784개의 입력을 받는 100개의 뉴런 생성
        self.params['W1'] = weight_init_std = np.random.randn(input_size, hidden_size)
        self.params['b1'] = np.zeros(hidden_size)

        # 2층(출력층)의 매개변수 설정
        self.params['W2'] = weight_init_std = np.random.randn(hidden_size, output_size)
        self.params['b2'] = np.zeros(output_size)


    # 예측(소프트맥스 사용할 예정)
    def predict(self, x):
        # 가중치, 편향 불러오기
        W1, W2 = self.params['W1'], self.params['W2']
        b1, b2 = self.params['b1'], self.params['b2']

        # 1-1 1층의 내적 구하기
        z1 = np.dot(x, W1) + b1
        # 1-2 내적에 대한 활성화 함수 적용
        a1 = sigmoid(z1)

        # 2-1 2층의 내적 구하기
        z2 = np.dot(a1, W2) + b2
        # 2-2 출력에 대한 출력함수 소프트 맥스 사용
        y = softmax(z2)

        return y


    # 비용 함수, 손실 함수
    def loss(self, x, t):
        pred = self.predict(x)

        # 예측한 결과물, 정답에 대한 loss를 구하면 된다.
        return cross_entropy_error(pred, t)


    # 정확도 확인하기
    def accuracy(self, x, t):
        y = self.predict(x)
        y = np.argmax(y, axis=1) # axis=1 각각의 행에서 인덱스를 추출하기 위해
        t = np.argmax(t, axis=1)

        # 맞춘 것들의 데이터 개수를 np.sum
        accuracy = np.sum(y == t) / float(x.shape[0])


    # TwoLayerNet의 미분 수행 함수
    def numerical_gradient(self, x, t):
        loss_W = lambda W : self.loss(x, t)

        # 각 층에서 구해지는 기울기를 저장할 딕셔너리
        # 각각의 기울기가 어디를 향해야 하는지...
        grads = {}

        # 1층의 가중치들의 기울기(loss에 대한 W1의 기울기)
        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])
        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])

        # 2층의 가중치들의 기울기
        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])
        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])

        return grads

# 신경망 생성하기
input_size = 28*28
hidden_size = 100
output_size = 10 # MNIST 숫자의 개수만큼
net = TwoLayerNet(input_size=input_size, hidden_size=hidden_size, output_size=output_size)

# 돌리기전 데이터 모양 체크
print(net.params['W1'].shape)
print(net.params['b1'].shape)
print(net.params['W2'].shape)
print(net.params['b2'].shape)

# 100개의 데이터를 임의로 준비 
x = np.random.rand(100, 784) # 모양이 100장의 미니배치를 의미할 수 있다.
y = net.predict(x)

x.shape, y.shape

from tensorflow.keras import datasets
mnist = datasets.mnist

# 튜플 형태로 묶어주면 트레인과 테스트를 구분해준다.
(X_train, y_train), (X_test, y_test) = mnist.load_data()

X_train.shape, y_train.shape

X_test.shape, y_test.shape

y_train = y_train.reshape(-1, 1)
y_test = y_test.reshape(-1, 1)

from sklearn.preprocessing import OneHotEncoder

y_encoder = OneHotEncoder()
y_train_dummy = y_encoder.fit_transform(y_train).toarray()
y_test_dummy = y_encoder.fit_transform(y_test).toarray()

y_train_dummy

y_test_dummy

X_train = X_train.reshape(X_train.shape[0], -1)
X_train = X_train / 255.0
X_train.shape

X_test = X_test.reshape(X_test.shape[0], -1)
X_test = X_test / 255.0
X_test.shape

X_train.shape, X_test.shape

y_train_dummy.shape, y_test_dummy.shape

"""# 훈련

- 미니 배치 선정
- 반복 횟수
- 학습률
"""

# 반복 작업 시각화 라이브러리
from tqdm import tqdm_notebook

iter_nums = 10000
train_size = X_train.shape[0] # 배치를 만들기 위한 전체 데이터 개수
batch_size = 100 # 600개의 배치가 생긴다.
lr = 0.1

network = TwoLayerNet(input_size=28*28, hidden_size=50, output_size=10)

train_loss_list = []

for i in tqdm_notebook(range(iter_nums)):

    # 미니배치 획득
    batch_mask = np.random.choice(train_size, batch_size)

    X_batch = X_train[batch_mask] # 랜덤하게 100개의 데이터를 추출해서 배치 데이터로 만들기
    t_batch = y_train[batch_mask] # 랜덤하게 100개의 데이터를 추출해서 배치 데이터에 대한 정답 만들기

    # 기울기 계산
    # numerical_gradient 함수 내부에서 벌어지는 일
    # 1. 예측
    # 2. cross_entropy_error를 통한 loss 구하기
    # 3. 구해진 loss 값을 이용해 미분 수행
    grad = network.numerical_gradient(X_batch, t_batch)

    # 매개변수 갱신(경사 하강법 수행)
    for key in ('W1', 'b1', 'W2', 'b2'):
        network.params[key] -= lr * grad[key]

    # 학습 경과 기록
    # loss print
    loss = network.loss(X_batch, t_batch)
    train_loss_list.append(loss)
    print("Step {} => loss {}".format(i, loss))

iter_per_epoch = max(train_size / batch_size, 1)

for i in tqdm_notebook(range(iter_nums)):

    # 미니배치 획득
    batch_mask = np.random.choice(train_size, batch_size)

    X_batch = X_train[batch_mask]
    t_batch = y_train[batch_mask] 

    grad = network.numerical_gradient(X_batch, t_batch)

    for key in grad.keys():
        network.params[key] -= lr * grad[key]

    loss = network.loss(X_batch, t_batch)
    print("Loss : {}".format(loss))

    # 1에폭시 계산 즉 600번당 한번 꼴로 정확도 계산
    if i % iter_per_epoch == 0:
        train_acc = network.accuracy(X_train, y_train_dummy)
        test_acc = network.accuracy(X_test, y_test_dummy)
        print("train Accuracy : {} / test Accuracy : {}".format(train_acc, test_acc))

